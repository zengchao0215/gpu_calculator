# é«˜çº§è¶…å‚æ•°ç³»ç»Ÿä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

æ–°çš„é«˜çº§è¶…å‚æ•°ç³»ç»Ÿå·²æˆåŠŸé›†æˆåˆ°AIæ˜¾å­˜è®¡ç®—å™¨ä¸­ï¼Œæ”¯æŒå››ç§æ¨¡å‹ç±»å‹çš„ç²¾ç¡®æ˜¾å­˜è®¡ç®—å’Œæ™ºèƒ½ä¼˜åŒ–å»ºè®®ã€‚ç³»ç»Ÿç°åœ¨æä¾›äº†ç‹¬ç«‹çš„"é«˜çº§å¾®è°ƒ"ä¸»èœå•ï¼Œä¸ºä¸“ä¸šç”¨æˆ·æä¾›æ›´å¼ºå¤§çš„é…ç½®å’Œè®¡ç®—åŠŸèƒ½ã€‚

## ä¸»èœå•ç»“æ„

AIæ˜¾å­˜è®¡ç®—å™¨ç°åœ¨åŒ…å«ä¸‰ä¸ªä¸»è¦èœå•é¡¹ï¼š

### 1. NLP/è¯­è¨€æ¨¡å‹
- åŸºç¡€çš„è¯­è¨€æ¨¡å‹æ¨ç†å’Œè®­ç»ƒè®¡ç®—
- åŒ…å«æ¨ç†æ˜¾å­˜ã€è®­ç»ƒæ˜¾å­˜ã€å¾®è°ƒæ˜¾å­˜ã€GRPOæ˜¾å­˜ç­‰åŸºç¡€åŠŸèƒ½

### 2. å¤šæ¨¡æ€æ¨¡å‹
- å¤šæ¨¡æ€æ¨¡å‹çš„æ˜¾å­˜è®¡ç®—
- æ”¯æŒå›¾åƒ-æ–‡æœ¬ã€è§†é¢‘-æ–‡æœ¬ç­‰å¤šæ¨¡æ€åœºæ™¯

### 3. é«˜çº§å¾®è°ƒ â­ **æ–°å¢åŠŸèƒ½**
- **ä¸“ä¸šçš„è¶…å‚æ•°é…ç½®ç³»ç»Ÿ**
- **å››ç§æ¨¡å‹ç±»å‹çš„ç²¾ç¡®è®¡ç®—**
- **æ™ºèƒ½ä¼˜åŒ–å»ºè®®å’Œå‚æ•°éªŒè¯**
- **GPUæ¨èå’Œæˆæœ¬åˆ†æ**

## æ”¯æŒçš„æ¨¡å‹ç±»å‹

### 1. NLPæ¨¡å‹ (è‡ªç„¶è¯­è¨€å¤„ç†)
- **æ”¯æŒæ¶æ„**: Transformer, BERT, GPT, T5, LLaMA, ChatGLM
- **å…³é”®è¶…å‚æ•°**: 
  - æ¨¡å‹å¤§å°: 125M - 175B+
  - åºåˆ—é•¿åº¦: 512 - 32768 tokens
  - LoRAé…ç½®: rank 4-256, alpha 16-128
  - å­¦ä¹ ç‡: 1e-6 ~ 1e-4

### 2. å¤šæ¨¡æ€æ¨¡å‹
- **æ”¯æŒæ¶æ„**: CLIP, BLIP, LLaVA, GPT-4V, Flamingo
- **å…³é”®è¶…å‚æ•°**:
  - å›¾åƒåˆ†è¾¨ç‡: 224Ã—224 ~ 1024Ã—1024
  - Patchå¤§å°: 14Ã—14 ~ 32Ã—32
  - è§†è§‰/æ–‡æœ¬ç¼–ç å™¨é…ç½®
  - æ¨¡æ€èåˆç­–ç•¥

### 3. MoEæ¨¡å‹ (ä¸“å®¶æ··åˆ)
- **æ”¯æŒæ¶æ„**: Switch Transformer, GLaM, PaLM-2, DeepSeek-MoE
- **å…³é”®è¶…å‚æ•°**:
  - ä¸“å®¶æ•°é‡: 8-2048
  - æ¿€æ´»ä¸“å®¶æ•°: 1-8
  - è·¯ç”±ç­–ç•¥: Top-K, Switch, Expert Choice
  - è´Ÿè½½å‡è¡¡æƒé‡

### 4. CNNæ¨¡å‹ (å·ç§¯ç¥ç»ç½‘ç»œ)
- **æ”¯æŒæ¶æ„**: ResNet, EfficientNet, ConvNeXt, RegNet, DenseNet
- **å…³é”®è¶…å‚æ•°**:
  - è¾“å…¥å›¾åƒå°ºå¯¸: 224Ã—224 ~ 512Ã—512
  - æ‰¹æ¬¡å¤§å°: 32-512
  - å­¦ä¹ ç‡: 1e-4 ~ 1e-2
  - æ•°æ®å¢å¼ºç­–ç•¥

## ç²¾ç¡®æ•°å­¦è®¡ç®—å…¬å¼

### NLPæ¨¡å‹æ˜¾å­˜è®¡ç®—
```
æ€»æ˜¾å­˜ = æ¨¡å‹æƒé‡æ˜¾å­˜ + ä¼˜åŒ–å™¨æ˜¾å­˜ + æ¢¯åº¦æ˜¾å­˜ + æ¿€æ´»å€¼æ˜¾å­˜ + KVç¼“å­˜æ˜¾å­˜ + LoRAæ˜¾å­˜ + é¢„ç•™æ˜¾å­˜

å…¶ä¸­ï¼š
- æ¨¡å‹æƒé‡æ˜¾å­˜ = P Ã— B
- ä¼˜åŒ–å™¨æ˜¾å­˜ = P Ã— B Ã— M (Mä¸ºä¼˜åŒ–å™¨å€æ•°)
- æ¢¯åº¦æ˜¾å­˜ = P Ã— B
- æ¿€æ´»å€¼æ˜¾å­˜ = B Ã— S Ã— H Ã— L Ã— N
- KVç¼“å­˜æ˜¾å­˜ = 2 Ã— B Ã— S Ã— H Ã— L Ã— ç²¾åº¦å­—èŠ‚æ•°
- LoRAæ˜¾å­˜ = 2 Ã— Î£(r Ã— (d_in + d_out)) Ã— B
```

### å¤šæ¨¡æ€æ¨¡å‹æ˜¾å­˜è®¡ç®—
```
æ€»æ˜¾å­˜ = è§†è§‰æ˜¾å­˜ + æ–‡æœ¬æ˜¾å­˜ + èåˆæ˜¾å­˜ + å›¾åƒç‰¹å¾æ˜¾å­˜ + è·¨æ¨¡æ€æ³¨æ„åŠ›æ˜¾å­˜ + ä¼˜åŒ–å™¨æ˜¾å­˜ + æ¢¯åº¦æ˜¾å­˜ + é¢„ç•™æ˜¾å­˜

å…¶ä¸­ï¼š
- è§†è§‰æ˜¾å­˜ = (HÃ—WÃ—C + P_vision) Ã— B_precision
- æ–‡æœ¬æ˜¾å­˜ = P_text Ã— B_precision
- èåˆæ˜¾å­˜ = P_fusion Ã— B_precision
- å›¾åƒç‰¹å¾æ˜¾å­˜ = B Ã— (HÃ—W/PÂ²) Ã— D Ã— B_precision
- è·¨æ¨¡æ€æ³¨æ„åŠ›æ˜¾å­˜ = B Ã— S_text Ã— S_vision Ã— B_precision
```

### MoEæ¨¡å‹æ˜¾å­˜è®¡ç®—
```
æ€»æ˜¾å­˜ = è·¯ç”±å™¨æ˜¾å­˜ + æ¿€æ´»ä¸“å®¶æ˜¾å­˜ + è·¯ç”±æ¦‚ç‡æ˜¾å­˜ + ä¸“å®¶åˆ†é…æ˜¾å­˜ + è´Ÿè½½å‡è¡¡æ˜¾å­˜ + ä¼˜åŒ–å™¨æ˜¾å­˜ + æ¢¯åº¦æ˜¾å­˜ + é¢„ç•™æ˜¾å­˜

å…¶ä¸­ï¼š
- è·¯ç”±å™¨æ˜¾å­˜ = H Ã— E Ã— B_precision
- æ¿€æ´»ä¸“å®¶æ˜¾å­˜ = K Ã— P_expert Ã— B_precision
- è·¯ç”±æ¦‚ç‡æ˜¾å­˜ = B Ã— S Ã— E Ã— B_precision
- ä¸“å®¶åˆ†é…æ˜¾å­˜ = B Ã— S Ã— K Ã— B_precision
- è´Ÿè½½å‡è¡¡æ˜¾å­˜ = E Ã— B_precision
```

### CNNæ¨¡å‹æ˜¾å­˜è®¡ç®—
```
æ€»æ˜¾å­˜ = å·ç§¯å±‚æ˜¾å­˜ + ç‰¹å¾å›¾æ˜¾å­˜ + å…¨è¿æ¥å±‚æ˜¾å­˜ + BNæ˜¾å­˜ + æ•°æ®å¢å¼ºæ˜¾å­˜ + ä¼˜åŒ–å™¨æ˜¾å­˜ + æ¢¯åº¦æ˜¾å­˜ + é¢„ç•™æ˜¾å­˜

å…¶ä¸­ï¼š
- å·ç§¯å±‚æ˜¾å­˜ = (KÃ—KÃ—C_inÃ—C_out + C_out) Ã— B_precision
- ç‰¹å¾å›¾æ˜¾å­˜ = B Ã— Î£(H_i Ã— W_i Ã— C_i) Ã— B_precision
- å…¨è¿æ¥å±‚æ˜¾å­˜ = (D_in Ã— D_out + D_out) Ã— B_precision
- BNæ˜¾å­˜ = 4 Ã— C Ã— B_precision
- æ•°æ®å¢å¼ºæ˜¾å­˜ = B Ã— H Ã— W Ã— C Ã— B_precision Ã— 2
```

## æ™ºèƒ½ä¼˜åŒ–åŠŸèƒ½

### 1. å®æ—¶å‚æ•°éªŒè¯
é«˜çº§å¾®è°ƒç³»ç»Ÿæä¾›ä¸‰å±‚éªŒè¯æœºåˆ¶ï¼š

#### **é”™è¯¯æ£€æŸ¥** (çº¢è‰²æç¤º)
- å‚æ•°è¶…å‡ºæœ‰æ•ˆèŒƒå›´
- æ¶æ„å‚æ•°ä¸å…¼å®¹
- å¿…éœ€å‚æ•°ç¼ºå¤±
- æ•°å­¦çº¦æŸè¿åï¼ˆå¦‚éšè—å±‚ç»´åº¦å¿…é¡»èƒ½è¢«æ³¨æ„åŠ›å¤´æ•°æ•´é™¤ï¼‰

#### **è­¦å‘Šæç¤º** (æ©™è‰²æç¤º)
- å‚æ•°åœ¨æœ‰æ•ˆèŒƒå›´å†…ä½†ä¸åœ¨æœ€ä¼˜èŒƒå›´
- å¯èƒ½å½±å“æ€§èƒ½çš„é…ç½®
- èµ„æºåˆ©ç”¨ç‡ä¸ç†æƒ³çš„è®¾ç½®

#### **é…ç½®å»ºè®®** (è“è‰²æç¤º)
- åŸºäºæœ€ä½³å®è·µçš„å‚æ•°å»ºè®®
- é’ˆå¯¹ç‰¹å®šç¡¬ä»¶çš„ä¼˜åŒ–å»ºè®®
- æˆæœ¬æ•ˆç›Šä¼˜åŒ–å»ºè®®

### 2. æ™ºèƒ½ä¼˜åŒ–å»ºè®®ç³»ç»Ÿ

#### **æ˜¾å­˜ä¼˜åŒ–** (Memory Optimization)
- **é«˜ä¼˜å…ˆçº§**: æ˜¾å­˜ä¸è¶³çš„ç´§æ€¥ä¼˜åŒ–æ–¹æ¡ˆ
  - å‡å°‘æ‰¹æ¬¡å¤§å°
  - å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
  - ä½¿ç”¨æ›´æ¿€è¿›çš„é‡åŒ–
- **ä¸­ä¼˜å…ˆçº§**: æ˜¾å­˜ä½¿ç”¨ç‡ä¼˜åŒ–
  - è°ƒæ•´åºåˆ—é•¿åº¦
  - ä¼˜åŒ–LoRAé…ç½®
  - å¯ç”¨CPUå¸è½½
- **ä½ä¼˜å…ˆçº§**: å†…å­˜æ•ˆç‡æå‡
  - ç‰¹å¾å›¾é‡è®¡ç®—
  - æ¨¡å‹å¹¶è¡Œç­–ç•¥

#### **æ€§èƒ½ä¼˜åŒ–** (Performance Optimization)
- **è®¡ç®—æ•ˆç‡åˆ†æ**: åŸºäºé…ç½®è¯„ä¼°è®¡ç®—æ•ˆç‡
- **ä¼˜åŒ–å™¨å»ºè®®**: é’ˆå¯¹ä¸åŒæ¨¡å‹ç±»å‹çš„æœ€ä½³ä¼˜åŒ–å™¨é€‰æ‹©
- **å¹¶è¡Œç­–ç•¥**: æ•°æ®å¹¶è¡Œã€æ¨¡å‹å¹¶è¡Œã€åºåˆ—å¹¶è¡Œå»ºè®®
- **æ··åˆç²¾åº¦**: è‡ªåŠ¨æ··åˆç²¾åº¦è®­ç»ƒå»ºè®®

#### **æˆæœ¬ä¼˜åŒ–** (Cost Optimization)
- **ç¡¬ä»¶æˆæœ¬**: åŸºäºæ˜¾å­˜éœ€æ±‚æ¨èæœ€ç»æµçš„GPUé…ç½®
- **PEFTæ–¹æ³•**: å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯å»ºè®®
- **äº‘æœåŠ¡**: æŒ‰éœ€ä»˜è´¹vsè‡ªå»ºç¡¬ä»¶çš„æˆæœ¬åˆ†æ
- **è®­ç»ƒæ—¶é—´**: æ•ˆç‡vsæˆæœ¬çš„å¹³è¡¡å»ºè®®

#### **ç¨³å®šæ€§ä¼˜åŒ–** (Stability Optimization)
- **å­¦ä¹ ç‡è°ƒæ•´**: åŸºäºæ¨¡å‹ç±»å‹å’Œå¤§å°çš„å­¦ä¹ ç‡å»ºè®®
- **æ­£åˆ™åŒ–**: æƒé‡è¡°å‡ã€Dropoutç­‰æ­£åˆ™åŒ–å‚æ•°ä¼˜åŒ–
- **æ¢¯åº¦å¤„ç†**: æ¢¯åº¦è£å‰ªå’Œç´¯ç§¯ç­–ç•¥
- **ä¸“å®¶å‡è¡¡**: MoEæ¨¡å‹çš„è´Ÿè½½å‡è¡¡ä¼˜åŒ–

### 3. GPUæ¨èç³»ç»Ÿ

#### **æ™ºèƒ½åŒ¹é…ç®—æ³•**
ç³»ç»ŸåŸºäºä»¥ä¸‹å› ç´ è¿›è¡ŒGPUæ¨èï¼š
- **æ˜¾å­˜éœ€æ±‚**: ç²¾ç¡®çš„æ˜¾å­˜è®¡ç®—ç»“æœ
- **åˆ©ç”¨ç‡ç›®æ ‡**: 75%ä¸ºæœ€ä½³åˆ©ç”¨ç‡
- **æˆæœ¬æ•ˆç›Š**: æ€§èƒ½ä»·æ ¼æ¯”åˆ†æ
- **å¯ç”¨æ€§**: å¸‚åœºä¾›åº”æƒ…å†µ

#### **æ¨èç­‰çº§**
- **ğŸŸ¢ ä¼˜ç§€ (Excellent)**: åˆ©ç”¨ç‡60-80%ï¼Œæ€§ä»·æ¯”æœ€ä½³
- **ğŸŸ¡ è‰¯å¥½ (Good)**: åˆ©ç”¨ç‡45-85%ï¼Œæ€§èƒ½å……è¶³
- **ğŸŸ  å¯æ¥å— (Acceptable)**: åˆ©ç”¨ç‡85-95%ï¼Œæ¥è¿‘ä¸Šé™
- **ğŸ”´ ä¸è¶³ (Insufficient)**: åˆ©ç”¨ç‡>95%ï¼Œæ˜¾å­˜ä¸è¶³

#### **æ¨èç¤ºä¾‹**
```
æ˜¾å­˜éœ€æ±‚: 15.2GB
æ¨èé…ç½®:
ğŸŸ¢ RTX 4090 (24GB) - åˆ©ç”¨ç‡63% - æ€§ä»·æ¯”æœ€ä½³
ğŸŸ¡ RTX 4080 (16GB) - åˆ©ç”¨ç‡95% - æ¥è¿‘ä¸Šé™
ğŸŸ  A100 PCIe (40GB) - åˆ©ç”¨ç‡38% - æ€§èƒ½è¿‡å‰©
```

## ä½¿ç”¨æ–¹å¼

### 1. Webç•Œé¢
1. æ‰“å¼€AIæ˜¾å­˜è®¡ç®—å™¨ä¸»é¡µé¢
2. ç‚¹å‡»é¡¶éƒ¨çš„ **"é«˜çº§å¾®è°ƒ"** ä¸»èœå•æ ‡ç­¾
3. é€‰æ‹©æ¨¡å‹ç±»å‹ï¼ˆNLP/å¤šæ¨¡æ€/MoE/CNNï¼‰
4. åœ¨é…ç½®é¢æ¿ä¸­é€‰æ‹©ï¼š
   - **åŸºç¡€é…ç½®**: æ ¸å¿ƒå‚æ•°è®¾ç½®
   - **é«˜çº§é…ç½®**: è¯¦ç»†æ¶æ„å‚æ•°
   - **ä¼˜åŒ–è®¾ç½®**: æ€§èƒ½å’Œç¨³å®šæ€§å‚æ•°
5. å®æ—¶æŸ¥çœ‹ï¼š
   - ç²¾ç¡®çš„æ˜¾å­˜è®¡ç®—ç»“æœ
   - å‚æ•°éªŒè¯å’Œé”™è¯¯æç¤º
   - æ™ºèƒ½ä¼˜åŒ–å»ºè®®
   - GPUæ¨èå’Œæˆæœ¬åˆ†æ

### 2. MCP APIè°ƒç”¨

#### æ–°å¢APIæ¥å£ï¼š`calculate_advanced_finetuning_vram`

è¿™æ˜¯ä¸“é—¨ä¸ºé«˜çº§å¾®è°ƒåŠŸèƒ½è®¾è®¡çš„MCPå·¥å…·æ¥å£ï¼Œæ”¯æŒå››ç§æ¨¡å‹ç±»å‹çš„ç²¾ç¡®è®¡ç®—ã€‚

**æ¥å£åœ°å€**: `POST /api/mcp/tools/call`

**å·¥å…·åç§°**: `calculate_advanced_finetuning_vram`

**å¿…éœ€å‚æ•°**:
- `modelType`: æ¨¡å‹ç±»å‹ ("nlp" | "multimodal" | "moe" | "cnn")
- `modelSize`: æ¨¡å‹å¤§å°(B)
- `architectureType`: æ¶æ„ç±»å‹
- `precision`: è®­ç»ƒç²¾åº¦ ("fp32" | "fp16" | "bf16" | "int8" | "int4")
- `batchSize`: æ‰¹æ¬¡å¤§å°
- `learningRate`: å­¦ä¹ ç‡
- `optimizer`: ä¼˜åŒ–å™¨ç±»å‹ ("sgd" | "adam" | "adamw")
- `trainingEpochs`: è®­ç»ƒè½®æ•°

**å¯é€‰å‚æ•°**ï¼ˆæ ¹æ®æ¨¡å‹ç±»å‹ï¼‰:
- NLP: `sequenceLength`, `hiddenSize`, `numLayers`, `loraRank`, `loraAlpha`
- å¤šæ¨¡æ€: `imageResolution`, `patchSize`, `visionFeatureDim`
- MoE: `numExperts`, `numActiveExperts`, `expertCapacityFactor`
- CNN: `inputImageSize`, `kernelSize`

**ç¤ºä¾‹è°ƒç”¨**:

```bash
# NLPæ¨¡å‹ - LLaMA-7B LoRAå¾®è°ƒ
curl -X POST http://localhost:3000/api/mcp/tools/call \
  -H "Content-Type: application/json" \
  -d '{
    "name": "calculate_advanced_finetuning_vram",
    "arguments": {
      "modelType": "nlp",
      "modelSize": 7.0,
      "architectureType": "LLaMA",
      "precision": "fp16",
      "batchSize": 4,
      "sequenceLength": 2048,
      "learningRate": 2e-5,
      "optimizer": "adamw",
      "trainingEpochs": 3,
      "hiddenSize": 4096,
      "numLayers": 32,
      "loraRank": 16,
      "loraAlpha": 32
    }
  }'

# å¤šæ¨¡æ€æ¨¡å‹ - LLaVAå¾®è°ƒ
curl -X POST http://localhost:3000/api/mcp/tools/call \
  -H "Content-Type: application/json" \
  -d '{
    "name": "calculate_advanced_finetuning_vram",
    "arguments": {
      "modelType": "multimodal",
      "modelSize": 7.0,
      "architectureType": "LLaVA",
      "precision": "fp16",
      "batchSize": 8,
      "sequenceLength": 1024,
      "learningRate": 1e-5,
      "optimizer": "adamw",
      "trainingEpochs": 5,
      "imageResolution": 336,
      "patchSize": 14,
      "visionFeatureDim": 1024
    }
  }'

# MoEæ¨¡å‹ - Switch Transformer
curl -X POST http://localhost:3000/api/mcp/tools/call \
  -H "Content-Type: application/json" \
  -d '{
    "name": "calculate_advanced_finetuning_vram",
    "arguments": {
      "modelType": "moe",
      "modelSize": 8.0,
      "architectureType": "Switch Transformer",
      "precision": "bf16",
      "batchSize": 16,
      "sequenceLength": 2048,
      "learningRate": 3e-5,
      "optimizer": "adamw",
      "trainingEpochs": 2,
      "numExperts": 8,
      "numActiveExperts": 2,
      "expertCapacityFactor": 1.25
    }
  }'

# CNNæ¨¡å‹ - ResNetå¾®è°ƒ
curl -X POST http://localhost:3000/api/mcp/tools/call \
  -H "Content-Type: application/json" \
  -d '{
    "name": "calculate_advanced_finetuning_vram",
    "arguments": {
      "modelType": "cnn",
      "modelSize": 0.05,
      "architectureType": "ResNet",
      "precision": "fp32",
      "batchSize": 64,
      "learningRate": 1e-3,
      "optimizer": "sgd",
      "trainingEpochs": 100,
      "inputImageSize": 224,
      "kernelSize": 3
    }
  }'
```

**è¿”å›ç»“æœæ ¼å¼**:
```json
{
  "content": [{
    "type": "text",
    "text": "{
      \"totalVRAM\": 15.2,
      \"breakdown\": {
        \"modelWeights\": 7.0,
        \"optimizer\": 4.2,
        \"gradients\": 1.8,
        \"activations\": 1.5,
        \"kvCache\": 0.5,
        \"other\": 0.2
      },
      \"recommendations\": {
        \"gpus\": [...],
        \"optimizations\": [...]
      },
      \"metadata\": {
        \"modelType\": \"NLP\",
        \"optimizationSuggestions\": [...],
        \"memoryEfficiency\": 85.3,
        \"computeEfficiency\": 72.1,
        \"hardwareRecommendations\": [...]
      }
    }"
  }]
}
```

## é…ç½®ç¤ºä¾‹

### LLaMA-7B LoRAå¾®è°ƒ
```typescript
const nlpConfig = {
  modelSize: 7.0,
  architectureType: 'LLaMA',
  precision: 'FP16',
  batchSize: 4,
  sequenceLength: 2048,
  learningRate: 2e-5,
  optimizer: 'AdamW',
  loraRank: 16,
  loraAlpha: 32,
  loraTargetModules: ['q_proj', 'v_proj']
};
```

### LLaVAå¤šæ¨¡æ€å¾®è°ƒ
```typescript
const multimodalConfig = {
  modelSize: 7.0,
  architectureType: 'LLaVA',
  imageResolution: 336,
  patchSize: 14,
  batchSize: 8,
  visionEncoderType: 'ViT',
  textEncoderType: 'BERT'
};
```

### Switch Transformer MoEå¾®è°ƒ
```typescript
const moeConfig = {
  modelSize: 8.0,
  architectureType: 'Switch Transformer',
  numExperts: 8,
  numActiveExperts: 2,
  expertCapacityFactor: 1.25,
  routingStrategy: 'Top-K'
};
```

### ResNet CNNå¾®è°ƒ
```typescript
const cnnConfig = {
  modelSize: 0.05,
  architectureType: 'ResNet',
  inputImageSize: 224,
  batchSize: 64,
  learningRate: 1e-3,
  optimizer: 'SGD'
};
```

## æŠ€æœ¯ç‰¹æ€§

- âœ… **ç²¾ç¡®è®¡ç®—**: åŸºäºä¸¥è°¨çš„æ•°å­¦å…¬å¼ï¼Œé¿å…è¿‘ä¼¼ä¼°ç®—
- âœ… **å®æ—¶éªŒè¯**: é…ç½®å‚æ•°çš„å®æ—¶éªŒè¯å’Œé”™è¯¯æç¤º
- âœ… **æ™ºèƒ½å»ºè®®**: AIé©±åŠ¨çš„ä¼˜åŒ–å»ºè®®ç³»ç»Ÿ
- âœ… **GPUæ¨è**: åŸºäºéœ€æ±‚çš„ç¡¬ä»¶æ¨è
- âœ… **MCPå…¼å®¹**: æ ‡å‡†åŒ–çš„APIæ¥å£
- âœ… **ç±»å‹å®‰å…¨**: å®Œæ•´çš„TypeScriptç±»å‹å®šä¹‰
- âœ… **å“åº”å¼UI**: ç°ä»£åŒ–çš„ç”¨æˆ·ç•Œé¢

## æ³¨æ„äº‹é¡¹

1. **å‚æ•°èŒƒå›´**: è¯·ç¡®ä¿å‚æ•°åœ¨æ¨èèŒƒå›´å†…ä»¥è·å¾—æœ€ä½³ç»“æœ
2. **æ˜¾å­˜é¢„ç•™**: ç³»ç»Ÿä¼šè‡ªåŠ¨é¢„ç•™1-2GBæ˜¾å­˜ç”¨äºç³»ç»Ÿå¼€é”€
3. **ä¼˜åŒ–å»ºè®®**: å»ºè®®ä¼˜å…ˆé‡‡ç”¨é«˜ä¼˜å…ˆçº§çš„ä¼˜åŒ–å»ºè®®
4. **ç¡¬ä»¶å…¼å®¹**: ç¡®ä¿é€‰æ‹©çš„GPUæ”¯æŒæ‰€éœ€çš„ç²¾åº¦ç±»å‹

## æ›´æ–°æ—¥å¿—

- **v1.0.0**: åˆå§‹ç‰ˆæœ¬ï¼Œæ”¯æŒå››ç§æ¨¡å‹ç±»å‹çš„ç²¾ç¡®è®¡ç®—
- å®Œæ•´çš„è¶…å‚æ•°é…ç½®ç³»ç»Ÿ
- æ™ºèƒ½ä¼˜åŒ–å»ºè®®åŠŸèƒ½
- MCPå·¥å…·é›†æˆ
- å®æ—¶å‚æ•°éªŒè¯
